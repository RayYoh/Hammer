<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="HAMMER: Harnessing MLLMs via Cross-Modal Integration for Intention-Driven 3D Affordance Grounding">
  <meta name="keywords" content="HAMMER, 3D Affordance Grounding, MLLMs, 3D Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HAMMER - Lei Yao</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/hammer.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  <link rel="stylesheet" href="static/css/style.css"> <!-- Resource style -->
  <script src="static/js/modernizr.js"></script> <!-- Modernizr -->
</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://rayyoh.github.io/">
        <span class="icon"> <i class="fas fa-home"></i> </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link"> More Research </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://rayyoh.github.io/SGIFormer"> SGIFormer </a>
          <a class="navbar-item" href="https://github.com/RayYoh/LaSSM"> LaSSM </a>
          <a class="navbar-item" href="https://rayyoh.github.io/GaussianCross"> GaussianCross </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
            <img src="static/images/hammer.png" alt="HAMMER" style="width: 48px; height: auto; vertical-align: text-top; margin-right: 10px; transform: translateY(-2px);" />
            <span style="color:rgba(74, 77, 163, 0.797); font-weight: bold; font-size: 1.2em;">HAMMER</span><br>
            Harnessing MLLMs via Cross-Modal Integration for Intention-Driven 3D Affordance Grounding
          </h1>
          <h3 class="title is-4" style="color: #5c5c5c;">CVPR 2026</h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://rayyoh.github.io/">Lei Yao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Yong_Chen22">Yong Chen</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~YUEJIAO_SU1">Yuejiao Su</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://wangyintu.github.io/">Yi Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://lmomoy.github.io/">Moyun Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.eie.polyu.edu.hk/~lpchau/">Lap-Pui Chau</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong Polytechnic University</span>
            <span class="author-block"><sup>2</sup>Huazhong University of Science and Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2602.xxxxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> <i class="fas fa-file-alt"></i> </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2602.xxxxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> <i class="ai ai-arxiv"></i> </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href="https://github.com/RayYoh/Hammer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> <i class="fab fa-github"></i> </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Weights Link. -->
              <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/RayYoh/Hammer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> 
                    <img src="static/images/hf_icon.svg" style="width: 1.1em; height: 1.1em; max-width: none; vertical-align: middle;"/>
                  </span>
                  <span>Weights</span>
                </a>
              </span>
              <!-- BibTeX Link. -->
              <span class="link-block">
                <a href="#BibTeX"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> <i class="fas fa-quote-right"></i> </span>
                  <span>BibTeX</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- TLDR Section -->
<section class="hero" id="tldr">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width" style="padding: 25px;">
                <div class="tldr-box"  
                     style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 5px solid #4a90e2; 
                                    padding: 20px; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
                    <h4 class="title is-4" style="margin-bottom: 10px;">TL;DR:</h4>
                    <p class="is-size-5">We present HAMMER, a novel approach that harnesses Multi-modal Large Language Models (MLLMs) to ground 3D affordances through cross-modal integration for intention-driven object interaction understanding.</p>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Paper abstract -->
<section class="section hero" style="padding-top: 1rem; padding-bottom: 1rem;">
    <div class="container is-max-desktop">
         <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p class="is-size-5">
                      Humans commonly identify 3D object affordance through observed interactions in images or videos, and once formed, such knowledge can be generically generalized to novel objects. Inspired by this principle, we advocate for a novel framework that leverages emerging multimodal large language models (MLLMs) for interaction intention-driven 3D affordance grounding, namely <strong>HAMMER</strong>. Instead of generating explicit object attribute descriptions or relying on off-the-shelf 2D segmenters, we alternatively aggregate the interaction intention depicted in the image into a contact-aware embedding and guide the model to infer textual affordance labels, ensuring it thoroughly excavates object semantics and contextual cues. We further devise a hierarchical cross-modal integration mechanism to fully exploit the complementary information from the MLLM for 3D representation refinement and introduce a multi-granular geometry lifting module that infuses spatial characteristics into the extracted intention embedding, thus facilitating accurate 3D affordance localization. Extensive experiments on public datasets and our newly constructed corrupted benchmark demonstrate the superiority and robustness of <strong>HAMMER</strong> compared to existing approaches.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
        <h2 class="title is-2">Pipeline</h2>
    </div>
</section>
<section class="section" id="Pipeline">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-full-width">
                <div class="box" style="margin-top: 0; margin-bottom: 1rem;">
                    <img src="./static/images/overview.png" alt="Pipeline">
                </div>
                <div class="content has-text-justified">
                    <p><b>The overall architecture of HAMMER.</b> Given a 3D point cloud \(\mathbf{P}\) and its corresponding interaction image \(\mathbf{I}\), our framework first processes \(\mathbf{I}\) through a pre-trained MLLM \(\mathcal{F}_{\theta}\) to extract an affordance-guided intention embedding \(\mathbf{f}_c\). This embedding is then used to enhance point cloud features via a hierarchical cross-modal integration mechanism. To imbue \(\mathbf{f}_c\) with 3D spatial awareness, we apply a multi-granular geometry lifting module that incorporates multi-scale geometric cues. Finally, the refined point features \(\tilde{\mathbf{f}}_p\) and the 3D-aware intention embedding \(\mathbf{f}_c^{3D}\) are decoded to produce the final affordance map \(\mathbf{p}\).</p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
        <h2 class="title is-2">Visualization</h2>
    </div>
</section>

<section class="section" id="Visualization">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-full-width">
                <div class="box">
                    <h4 class="title is-4" style="color:rgba(74, 77, 163, 0.797)">Predictions on PIAD dataset.</h4>
                    <div class="content has-text-centered">
                        <img src="./static/images/vis_piad.png" alt="PIAD Dataset Visualization" width="100%"/>
                    </div>
                </div>
                <div class="box">
                    <h4 class="title is-4" style="color:rgba(74, 77, 163, 0.797)">Results on PIAD v2 seen classes</h4>
                    <div class="content has-text-centered">
                        <img src="./static/images/vis_piadv2_seen.png" alt="PIAD v2 Seen Visualization" width="100%"/>
                    </div>
                </div>
                <div class="box">
                    <h4 class="title is-4" style="color:rgba(74, 77, 163, 0.797)">Zero-shot generalization on PIAD v2 unseen splits</h4>
                    <div class="content has-text-centered">
                        <img src="./static/images/vis_piadv2_unseen.png" alt="PIAD v2 Unseen Visualization" width="100%"/>
                    </div>
                </div>
                <div class="box">
                    <h4 class="title is-4" style="color:rgba(74, 77, 163, 0.797)">Effectiveness of the feature integration</h4>
                    <div class="content has-text-centered">
                        <img src="./static/images/vis_feat.png" alt="Effectiveness" width="100%"/>
                    </div>
                </div>
            </div>
        </div>
    </div> 
</section>

<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
        <h2 class="title is-2">Experiments</h2>
    </div>
</section>

<section class="section" id="Experiments">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-full-width">                
                <div class="box">
                    <h3 class="title is-4">Quantitative results on PIAD dataset</h3>
                    <div class="content has-text-centered">
                        <img src="./static/images/tab_piad.png" alt="PIAD Results" width="100%"/>
                    </div>
                </div>

                <div class="box">
                    <h3 class="title is-4">Quantitative results on PIAD v2 dataset</h3>
                    <div class="content has-text-centered">
                        <img src="./static/images/tab_piadv2.png" alt="PIAD v2 Results" width="100%"/>
                    </div>
                </div>

                <div class="columns is-vcentered">
                    <div class="column" style="flex: 0 0 40%; display: flex; flex-direction: column; justify-content: space-between;">
                        <div class="box" style="margin-bottom: 1rem;">
                            <h4 class="title is-6">Robustness evaluation</h4>
                            <div class="content has-text-centered">
                                <img src="./static/images/vis_robustness.png" alt="Robustness Evaluation" width="100%"/>
                            </div>
                        </div>
                        <div class="box" style="margin-bottom: 0;">
                            <h4 class="title is-6">Quantitative results</h4>
                            <div class="content has-text-centered">
                                <img src="./static/images/tab_robust.png" alt="Robustness Comparison" width="100%"/>
                            </div>
                        </div>
                    </div>
                    <div class="column" style="flex: 0 0 60%;">
                        <div class="box" style="height: 100%; margin-bottom: 0;">
                            <h3 class="title is-5">More qualitative results on the corrupted benchmark</h3>
                            <div class="content has-text-centered">
                                <img src="./static/images/vis_geal.png" alt="Qualitative Corrupted" width="100%"/>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div> 
</section>

<section class="section" id="Acknowledgment">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgment üëè</h2>
      <p>The research work described in this paper was conducted in the JC STEM Lab of Machine Learning and Computer Vision funded by The Hong Kong Jockey Club Charities Trust. This research received partially support from the Global STEM Professorship Scheme from the Hong Kong Special Administrative Region.</p>
    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX üìù</h2>
        <pre><code>@inproceedings{yao2026hammer,
  title={HAMMER: Harnessing MLLMs via Cross-Modal Integration for Intention-Driven 3D Affordance Grounding},
  author={Yao, Lei and Chen, Yong and Su, Yuejiao and Wang, Yi and Liu, Moyun and Chau, Lap-Pui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2026}
}</code></pre>
    </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-8">
        <div class="content">
          <a style="color:hsla(247, 58%, 62%, 0.862)" href="#top"><i class="fa fa-arrow-up"></i><br/>Top</a>
          <p>
            Website from <a style="color:hsla(247, 58%, 62%, 0.862)" href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> under <a style="color:hsla(247, 61%, 57%, 0.862)"
            href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0
            International</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>